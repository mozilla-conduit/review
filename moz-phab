#!/usr/bin/env python2
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.

# coding=utf-8

"""
Wrapper around Phabricator's `arc` cli to support submission of a series of commits.

Goals:
- must only use standard libraries
- must be a single file for easy deployment
- should work on python 2.7 and python 3.5+
"""

import ConfigParser
import argparse
import calendar
import datetime
import errno
import io
import json
import logging
import os
import re
import ssl
import stat
import subprocess
import sys
import tempfile
import time
import traceback
import urllib2
import uuid
from distutils.version import LooseVersion

# Known Issues
# - reordering, folding, etc commits doesn't result in the stack being updated
#   correctly on phabricator, or may outright fail due to dependency loops.
#   to address this we'll need to query phabricator's api directly and clear
#   dependencies prior to calling arc. we'd probably also have to
#   abandon revisions that are no longer part of the stack.  unfortunately
#   phabricator's api currently doesn't expose calls to do this.
# - commits with a description already modified by arc (ie. the follow the arc commit
#   description template with 'test plan', subscribers, etc) are not handled by this
#   script.  commits in this format should be detected and result in the commit being
#   rejected.  ideally this should extract the title, body, reviewers, and bug-id
#   from the arc template and reformat to the standard mozilla format.


# Environment Vars

DEBUG = bool(os.getenv("DEBUG"))
IS_WINDOWS = sys.platform == "win32"
HAS_ANSI = not IS_WINDOWS and (
    (hasattr(sys.stdout, "isatty") and sys.stdout.isatty())
    or os.getenv("TERM", "") == "ANSI"
    or os.getenv("PYCHARM_HOSTED", "") == "1"
)
SELF_FILE = os.getenv("UPDATE_FILE") if os.getenv("UPDATE_FILE") else __file__

# Constants and Globals

logger = logging.getLogger("moz-phab")
config = None

# Where to direct people when `arc` isn't installed.
GUIDE_URL = (
    "https://moz-conduit.readthedocs.io/en/latest/phabricator-user.html#quick-start"
)

# Auto-update
SELF_REPO = "mozilla-conduit/review"
SELF_UPDATE_FREQUENCY = 24 * 3  # hours
ARC_UPDATE_FREQUENCY = 24 * 7  # hours

# Environment names (display purposes only)
PHABRICATOR_URLS = {
    "https://phabricator.services.mozilla.com/": "Phabricator",
    "https://phabricator-dev.allizom.org/": "Phabricator-Dev",
}

# arc related consts.
ARC_COMMIT_DESC_TEMPLATE = """
{title}

Summary:
{body}

{depends_on}

Test Plan:

Reviewers: {reviewers}

Subscribers:

Bug #: {bug_id}
""".strip()
ARC_OUTPUT_REV_URL_RE = re.compile(r"^\s*Revision URI: (http.+)$", flags=re.MULTILINE)
ARC_DIFF_REV_RE = re.compile(
    r"^\s*Differential Revision:\s*https://.+/D(\d+)\s*$", flags=re.MULTILINE
)

# If a commit body matches **all** of these, reject it.  This is to avoid the
# necessity to merge arc-style fields across an existing commit description
# and what we need to set.
ARC_REJECT_RE_LIST = [
    re.compile(r"^Summary:", flags=re.MULTILINE),
    re.compile(r"^Reviewers:", flags=re.MULTILINE),
]

# Bug and review regexs (from vct's commitparser)
BUG_ID_RE = re.compile(r"(?:(?:bug|b=)(?:\s*)(\d+)(?=\b))", flags=re.IGNORECASE)
LIST = r"[;,\/\\]\s*"
LIST_RE = re.compile(LIST)
IRC_NICK = (
    r"[a-zA-Z0-9\-\_!]+"
)  # Note this includes !, which is different from commitparser
REVIEWERS_RE = re.compile(
    r"([\s(.\[;,])(r[=?])("
    + IRC_NICK
    + r"(?:"
    + LIST
    + r"(?![a-z0-9.\-]+[=?])"
    + IRC_NICK
    + r")*)?"
)
R_SPECIFIER_RE = re.compile(r"\br[=?]")

MINIMUM_MERCURIAL_VERSION = LooseVersion("4.3.3")

#
# Utilities
#


def getXDGdir():
    platform = sys.platform
    default = os.path.expanduser("~")
    if platform == "linux" or platform == "linux2":
        default = os.path.join(default, ".config")
        path = os.getenv("XDG_CONFIG_HOME", default)
    elif platform == "darwin":  # MACOS
        default = os.path.join(default, "Library", "Preferences")
        path = os.getenv("XDG_CONFIG_HOME", default)
    elif platform == "win32" or platform == "win64":
        default = os.path.join(default, "AppData")
        path = os.getenv("APPDATA", default)
    return path


def which(filename):
    # backport of shutil.which from py3
    seen = set()
    for path in os.environ.get("PATH", os.defpath).split(os.pathsep):
        path = os.path.expanduser(path)
        norm_path = os.path.normcase(path)
        if norm_path not in seen:
            seen.add(norm_path)
            fn = os.path.join(path, filename)
            if (
                os.path.exists(fn)
                and os.access(fn, os.F_OK | os.X_OK)
                and not os.path.isdir(fn)
            ):
                return fn
    return None


def shell_quote(s):
    # backport of shutil.quote from py3
    # used for debugging output only
    _find_unsafe = re.compile(r"[^\w@%+=:,./-]").search
    if not s:
        return "''"
    if _find_unsafe(s) is None:
        return s
    return "'" + s.replace("'", "'\"'\"'").replace("\n", "\\n") + "'"


def parse_zulu_time(timestamp):
    """Parse YYYY-MM-DDTHH:mm:SSZ date string, return as epoch seconds in local tz."""
    return calendar.timegm(time.strptime(timestamp, "%Y-%m-%dT%H:%M:%SZ"))


def check_call(command, **kwargs):
    # wrapper around subprocess.check_call with debug output
    logger.debug("$ %s" % " ".join(shell_quote(s) for s in command))
    subprocess.check_call(command, **kwargs)


def check_output(command, cwd=None, split=True, strip=True, never_log=False):
    # wrapper around subprocess.check_output with debug output and splitting
    logger.debug("$ %s" % " ".join(shell_quote(s) for s in command))
    try:
        output = subprocess.check_output(command, cwd=cwd)
    except subprocess.CalledProcessError as e:
        logger.debug(e.output)
        raise Exception("command '%s' failed to complete successfully" % command[0])
    if strip:
        output = output.rstrip()
    if output and not never_log:
        logger.debug(output)
    return output.splitlines() if split else output


def read_json_field(files, field_path):
    """Parses json files in turn returning value as per field_path, or None."""
    for filename in files:
        try:
            with open(filename) as f:
                rc = json.load(f)
                for field_name in field_path:
                    if field_name not in rc:
                        rc = None
                        break
                    rc = rc[field_name]
                if not rc:
                    continue
                return rc
        except IOError as e:
            if e.errno == errno.ENOENT:
                continue
            raise
        except ValueError:
            continue
    return None


def get_char():
    try:
        # POSIX-based systems.
        import tty
        import termios

        fd = sys.stdin.fileno()
        old_term_attrs = None
        try:
            old_term_attrs = termios.tcgetattr(fd)
            tty.setcbreak(fd)
            return sys.stdin.read(1)
        except termios.error:
            # Fallback on readline() if we failed to put the terminal into raw mode.
            return sys.stdin.readline().strip().lower()
        finally:
            if old_term_attrs:
                termios.tcsetattr(fd, termios.TCSADRAIN, old_term_attrs)
    except ImportError:
        # Windows-based systems.
        import msvcrt

        return msvcrt.getch()


def prompt(question, options):
    if HAS_ANSI:
        question = "\033[33m%s\033[0m" % question
    options[0] = options[0].upper()
    sys.stdout.write("%s (%s)? " % (question, "/".join(options)))
    sys.stdout.flush()

    res = ""
    default = options[0][0].lower()
    options = {o[0].lower(): o for o in options}
    while res not in options:
        res = get_char()
        if res in (chr(10), chr(13)):  # return
            res = default
        elif res == chr(3) or res == chr(27):  # ^C, escape
            print("^C")
            sys.exit(1)
        if res in options:
            print(options[res])

    return options[res]


class NamedTemporaryFile(object):
    """
    Like tempfile.NamedTemporaryFile except it works on Windows
    in the case where you open the created file a second time.

    From mozilla-central:testing/mozbase/mozfile/mozfile/mozfile.py with
    slight modifications.
    """

    def __init__(self):
        fd, path = tempfile.mkstemp()
        os.close(fd)

        self.file = open(path, "w+b")
        self._path = path
        self._delete = True
        self._unlinked = False

    def __getattr__(self, k):
        return getattr(self.__dict__["file"], k)

    def __iter__(self):
        return self.__dict__["file"]

    def __enter__(self):
        self.file.__enter__()
        return self

    def __exit__(self, exc, value, tb):
        self.file.__exit__(exc, value, tb)
        if self.__dict__["_delete"]:
            os.unlink(self.__dict__["_path"])
            self._unlinked = True

    def __del__(self):
        if self.__dict__["_unlinked"]:
            return
        self.file.__exit__(None, None, None)
        if self.__dict__["_delete"]:
            os.unlink(self.__dict__["_path"])


class Error(Exception):
    """Errors thrown explictly by this script; won't generate a stack trace."""


#
# Configuration
#


class Config(object):
    def __init__(self, should_access_file=True):
        self._filename = os.path.join(getXDGdir(), "moz-phab-config.ini")
        self.name = "moz-phab-config.ini"  # human-readable name

        # Default values.
        defaults = u"""
            [ui]
            no_ansi=false

            [arc]
            arc_command=arc

            [submit]
            auto_submit=false
            always_blocking=false
            warn_untracked=true

            [updater]
            self_last_check=0
            arc_last_check=0
            """

        self._config = ConfigParser.SafeConfigParser()
        self._config.readfp(
            io.StringIO("\n".join([l.strip() for l in defaults.splitlines()]))
        )

        # the `arc_command` default value depends on the operating system
        if IS_WINDOWS:
            self._set("arc", "arc_command", "arc.bat")

        if should_access_file:
            self._config.read([self._filename])

        self.no_ansi = self._config.getboolean("ui", "no_ansi")
        self.arc_command = self._config.get("arc", "arc_command")
        self.auto_submit = self._config.getboolean("submit", "auto_submit")
        self.always_blocking = self._config.getboolean("submit", "always_blocking")
        self.warn_untracked = self._config.getboolean("submit", "warn_untracked")
        self.self_last_check = self._config.getint("updater", "self_last_check")
        self.arc_last_check = self._config.getint("updater", "arc_last_check")

        if should_access_file and not os.path.exists(self._filename):
            self.write()

        self.arc = [self.arc_command]

    def _set(self, section, option, value):
        if not self._config.has_section(section):
            self._config.add_section(section)
        self._config.set(section, option, str(value))

    def write(self):
        if os.path.exists(self._filename):
            logger.debug("updating %s" % self._filename)
            self._set("submit", "auto_submit", self.auto_submit)
            self._set("updater", "self_last_check", self.self_last_check)
            self._set("updater", "arc_last_check", self.arc_last_check)

        else:
            logger.debug("creating %s" % self._filename)
            self._set("ui", "no_ansi", self.no_ansi)
            self._set("arc", "arc_command", self.arc_command)
            self._set("submit", "auto_submit", self.auto_submit)
            self._set("submit", "always_blocking", self.always_blocking)
            self._set("submit", "warn_untracked", self.warn_untracked)

        with open(self._filename, "w") as f:
            self._config.write(f)


#
# Repository
#


def probe_repo(path):
    try:
        return Mercurial(path)
    except ValueError:
        pass

    try:
        return Git(path)
    except ValueError:
        pass

    return None


def repo_from_args(args):
    """Returns a Repository object from either args.path or the cwd"""

    repo = None

    # This allows users to override the below sanity checks.
    if hasattr(args, "path") and args.path:
        repo = probe_repo(args.path)
        if not repo:
            raise Error("%s: Not a repository: .hg / .git" % args.path)

    else:
        # Walk parents to find repository root.
        path = os.path.abspath(os.getcwd())
        while not repo and os.path.split(path)[1]:
            repo = probe_repo(path)
            path = os.path.abspath(os.path.join(path, os.path.pardir))
        if not repo:
            raise Error(
                "Not a repository (or any of the parent directories): .hg / .git"
            )

    repo.set_args(args)
    return repo


class Repository(object):
    def __init__(self, path, dot_path, phab_url=None):
        self.path = path  # base repository directory
        self.dot_path = dot_path  # .hg/.git directory
        self.args = None
        self.phab_url = phab_url or self._phab_url()

    def _phab_url(self):
        """Determine the phab/conduit URL."""

        # In order of priority as per arc
        arcconfig_files = [
            os.path.join(self.dot_path, ".arcconfig"),
            os.path.join(self.path, ".arcconfig"),
        ]
        if IS_WINDOWS:
            defaults_files = [
                os.path.join(os.getenv("APPDATA", ""), ".arcrc"),
                os.path.join(
                    os.getenv("ProgramData", ""), "Phabricator", "Arcanist", "config"
                ),
            ]
        else:
            defaults_files = ["/etc/arcconfig", os.path.expanduser("~/.arcrc")]
        phab_url = read_json_field(
            arcconfig_files, ["phabricator.uri"]
        ) or read_json_field(defaults_files, ["config", "default"])

        if not phab_url:
            raise Error("Failed to determine Phabricator URL (missing .arcconfig?)")
        return phab_url

    def cleanup(self):
        """Perform any repo-related cleanup tasks.

        May be called multiple times.
        If an exception is raised this is NOT called (to avoid dataloss)."""

    def set_args(self, args):
        self.args = args

    def untracked(self):
        """Return a list of untracked files."""

    def commit_stack(self):
        """Return list of commits.

        List of dicts with the following keys:
            name          human readable identifier of commit (eg. short sha)
            node          sha/hash
            title         first line of commit description (unaltered)
            body          commit description, excluding first line
            title-preview title with bug-id and reviewer modifications
            bug-id        bmo bug-id
            bug-id-orig   original bug-id from commit desc
            reviewers     list of reviewers
            rev-id        phabricator revision id
        """

    def refresh_commit_stack(self, commits):
        """Update the stack following an altering change (eg rebase)."""

    def checkout(self, node):
        """Checkout/Update to specified node."""

    def amend_commit(self, commit, commits):
        """Amend commit description from `title` and `desc` fields"""

    def rebase_commit(self, source_commit, dest_commit):
        """Rebase source onto destination."""

    def check_commits_for_submit(self, commits):
        """Validate the list of commits (from commit_stack) are ok to submit"""
        errors = []

        for commit in commits:
            commit_errors = []
            # TODO allow NOBUG in commit message (not in arg)
            # TODO be more relaxed if we're updating an existing rev?
            if not commit["bug-id"]:
                commit_errors.append("missing bug-id")

            if has_arc_rejections(commit["body"]):
                commit_errors.append("contains arc fields")

            if commit_errors:
                errors.append(
                    "%s %s\n- %s"
                    % (commit["name"], commit["title"], "\n- ".join(commit_errors))
                )

        if errors:
            raise Error("\n\n".join(errors))


#
# Mercurial
#


class Mercurial(Repository):
    def __init__(self, path):
        dot_path = os.path.join(path, ".hg")
        if not os.path.exists(dot_path):
            raise ValueError("%s: not a hg repository" % path)
        logger.debug("found hg repo in %s" % path)

        super(Mercurial, self).__init__(path, dot_path)

        self._hg = ["hg.exe" if IS_WINDOWS else "hg"]
        self.revset = None
        self.strip_nodes = []
        self.status = None

        # Normalise/standardise Mercurial's output.
        os.environ["HGPLAIN"] = "1"
        os.environ["HGENCODING"] = "UTF-8"

        # Check for `hg`, and mercurial version.
        if not which(self._hg[0]):
            raise Error("Failed to find 'hg' executable")
        m = re.search(
            r"\(version ([^)]+)\)", self.hg_out(["--version", "--quiet"], split=False)
        )
        if not m:
            raise Error("Failed to determine Mercurial version.")
        if LooseVersion(m.group(1)) < MINIMUM_MERCURIAL_VERSION:
            raise Error(
                "You are currently running Mercurial %s.  "
                "Mercurial %s or newer is required."
                % (m.group(1), MINIMUM_MERCURIAL_VERSION)
            )

        # Load hg config into hg_config.  We'll specify specific settings on
        # the command line when calling hg; all other user settings are ignored.
        hg_config = {}
        for line in self.hg_out(["config"], never_log=True):
            # On Windows mercurial.ini is likely to be cp1252 encoded, not UTF-8.
            if IS_WINDOWS:
                try:
                    line = line.decode("cp1252").encode("UTF-8")
                except UnicodeDecodeError:
                    pass

            name, value = line.split("=", 1)
            name = name.strip()
            value = value.strip()
            if not name.startswith("extensions.") or not value.startswith("!"):
                hg_config[name] = value

        # Need to use the correct username.
        if "ui.username" not in hg_config:
            raise Error("ui.username is not configured in your hgrc")
        self._hg.extend(["--config", "ui.username=%s" % hg_config["ui.username"]])

        # Always need rebase.
        self._hg.extend(["--config", "extensions.rebase="])

        # Enable evolve if the user's currently using it.  evolve makes amending
        # commits with children trivial (amongst other things).
        ext_evolve = self._get_extension("evolve", hg_config)
        if ext_evolve is not None:
            self._hg.extend(["--config", "extensions.evolve=%s" % ext_evolve])
            self.use_evolve = True

        # Otherwise just enable obsolescence markers, and when we're done remove
        # the obsstore we created.
        else:
            self._hg.extend(["--config", "experimental.evolution.createmarkers=true"])
            self._hg.extend(["--config", "extensions.strip="])
            self.use_evolve = False
            self.obsstore = os.path.join(self.path, ".hg", "store", "obsstore")
            self.unlink_obsstore = not os.path.exists(self.obsstore)

        # This script interacts poorly with mq.
        ext_mq = self._get_extension("mq", hg_config)
        self.has_mq = ext_mq is not None
        if self.has_mq:
            self._hg.extend(["--config", "extensions.mq=%s" % ext_mq])

        # `shelve` is useful for dealing with uncommitted changes; track if it's
        # currently enabled so we can tailor our error accordingly.
        self.has_shelve = self._get_extension("shelve", hg_config) is not None

        # Disable the user's hgrc file, to ensure we run without rogue extensions.
        os.environ["HGRCPATH"] = ""

    @staticmethod
    def _get_extension(extension, config):
        for prefix in ("extensions.%s", "extensions.hgext.%s"):
            field = prefix % extension
            if field in config:
                return config.get(field, "")

        return None

    def hg(self, command, **kwargs):
        return check_call(self._hg + command, cwd=self.path, **kwargs)

    def hg_out(self, command, **kwargs):
        return check_output(self._hg + command, cwd=self.path, **kwargs)

    def hg_log(self, revset, split=True, select="node"):
        return self.hg_out(["log", "-T", "{%s}\n" % select, "-r", revset], split=split)

    def cleanup(self):
        # Remove the store of obsolescence markers; if the user doesn't have evolve
        # installed mercurial will warn if this exists.
        if not self.use_evolve and self.unlink_obsstore:
            try:
                os.unlink(self.obsstore)
            except OSError as e:
                if e.errno != errno.ENOENT:
                    raise

        if self.strip_nodes:
            # With the obsstore deleted the amended nodes are no longer hidden, so
            # we need to strip them completely from the repo.
            self.hg(["strip"] + self.strip_nodes)
            self.strip_nodes = []

    def _status(self):
        # `hg status` is slow on large repos.  As we'll need both uncommitted changes
        # and untracked files separately, run it once and cache results.
        if self.status is None:
            self.status = dict(T=[], U=[])
            for line in self.hg_out(
                ["status", "--added", "--deleted", "--modified", "--unknown"],
                split=True,
            ):
                status, path = line.split(" ", 1)
                self.status["U" if status == "?" else "T"].append(path)
        return self.status

    def untracked(self):
        return self._status()["U"]

    def _refresh_commit(self, commit, node, rev=None):
        """Update commit's node and name from node and rev."""
        if not rev:
            rev = self.hg_log(node, select="rev", split=False)
        commit["node"] = node
        commit["name"] = "%s:%s" % (rev, node[:12])

    def refresh_commit_stack(self, commits):
        """Update all commits to point to their superseded commit."""
        for commit in commits:
            hg_log = self.hg_out(
                ["log"]
                + ["-T", "{rev} {node}\n"]
                + ["--hidden"]
                + ["-r", "successors(%s) and not obsolete()" % commit["node"]]
            )
            if hg_log:
                # Not sure the best way to handle multiple successors, so just bail out.
                if len(hg_log) > 1:
                    raise Error(
                        "Multiple successors found for %s, unable to continue"
                        % commit["node"]
                    )

                (rev, node) = hg_log[0].split(" ", 1)
                self._refresh_commit(commit, node, rev)

        self.revset = "%s::%s" % (commits[0]["node"], commits[-1]["node"])

        super(Mercurial, self).refresh_commit_stack(commits)

    def set_args(self, args):
        super(Mercurial, self).set_args(args)

        # Set the default start revision.
        if self.args.start_rev == "(auto)":
            start = "ancestors(.) and not public() and not obsolete()"
        else:
            start = self.args.start_rev

        # Resolve to nodes as that's nicer to read.
        try:
            start = self.hg_log(start)[0]
        except IndexError:
            if self.args.start_rev == "(auto)":
                raise Error("Failed to find draft commits to submit")
            else:
                raise Error("Failed to start of commit range: %s" % self.args.start_rev)
        try:
            end = self.hg_log(self.args.end_rev)[0]
        except IndexError:
            raise Error("Failed to end of commit range: %s" % self.args.end_rev)

        self.revset = "%s::%s" % (start[:12], end[:12])

    def commit_stack(self):
        # Grab all the info we need about the commits, using randomness as a delimiter.
        boundary = "--%s--\n" % uuid.uuid4().get_hex()
        hg_log = self.hg_out(
            ["log", "-T", "{rev} {node} {desc}%s" % boundary, "-r", self.revset],
            split=False,
            strip=False,
        )[: -len(boundary)]

        commits = []
        for log_line in hg_log.split(boundary):
            rev, node, desc = log_line.split(" ", 2)
            desc = desc.splitlines()

            commits.append(
                {
                    "name": "%s:%s" % (rev, node[:12]),
                    "node": node,
                    "title": desc[0],
                    "title-preview": desc[0],
                    "body": "\n".join(desc[1:]).rstrip(),
                    "bug-id": None,
                    "reviewers": [],
                    "rev-id": None,
                }
            )

        return commits

    def checkout(self, node):
        self.hg(["update", "--quiet", node])

    def _amend_commit_body(self, node, body):
        with NamedTemporaryFile() as temp_f:
            temp_f.write(body)
            temp_f.flush()

            self.checkout(node)
            self.hg(["commit", "--amend", "--logfile", temp_f.name])

    def amend_commit(self, commit, commits):
        updated_body = "%s\n%s" % (commit["title"], commit["body"])
        current_body = self.hg_out(
            ["log", "-T", "{desc}", "-r", commit["node"]], split=False
        )
        if current_body == updated_body:
            logger.debug("not amending commit %s, unchanged" % commit["name"])
            return False

        # Find our position in the stack.
        parent_node = None
        first_child = None
        is_parent = True
        for c in commits:
            if c["node"] == commit["node"]:
                is_parent = False
            elif is_parent:
                parent_node = c["node"]
            elif not first_child:
                first_child = c
                break

        # Track children of the last commit in the stack.
        post_stack_children = []
        if not first_child:
            post_stack_children = self.hg_log("children(%s)" % commit["node"])

        if self.use_evolve:
            # If evolve is installed this is trivial.

            # Amend and refresh the stack to get the new commit node.
            self._amend_commit_body(commit["node"], updated_body)
            self.refresh_commit_stack(commits)

            # Rebase children atop new commit node.
            if first_child:
                self.rebase_commit(first_child, commit)

        elif not first_child and not post_stack_children:
            # Without evolve things are much more exciting.

            # If there's no children we can just amend.

            self._amend_commit_body(commit["node"], updated_body)

            # This should always result in an amended node, but we need to be
            # extra careful not to strip the original node.
            amended_node = self.hg_log(".", split=False)
            if amended_node != commit["node"]:
                self.strip_nodes.append(commit["node"])

        else:
            # Brace yourself.  We need to create a dummy commit with the same parent as
            # the commit, rebase a copy of the commit onto the dummy, amend, rebase the
            # amended commit back onto the original parent, rebase the children onto
            # that, then strip the original commit and dummy commits.

            # Find a parent for the first commit in the stack
            if not parent_node:
                parent_node = self.hg_log("parents(%s)" % commit["node"])[0]

            # Create the dummy commit.
            self.checkout(parent_node)
            self.hg(
                ["commit"]
                + ["--message", "dummy"]
                + ["--config", "ui.allowemptycommit=true"]
            )
            dummy_node = self.hg_log(".", split=False)

            # Rebase a copy of this commit onto the dummy.
            self.hg(["rebase", "--keep", "--rev", commit["node"], "--dest", dummy_node])
            rebased_node = self.hg_log("children(.)", split=False)

            # Amend.
            self._amend_commit_body(rebased_node, updated_body)
            amended_node = self.hg_log(".", split=False)

            # Rebase back onto parent
            self.hg(["rebase"] + ["--source", amended_node] + ["--dest", parent_node])
            rebased_amended_node = self.hg_log(".", split=False)

            # Update the commit object now.
            original_node = commit["node"]
            self._refresh_commit(commit, rebased_amended_node)

            # Note what nodes need to be stripped when we're all done.
            self.strip_nodes.extend([original_node, dummy_node])

            # And rebase children.
            if first_child:
                self.rebase_commit(first_child, commit)

        # Ensure our view of the stack is up to date.
        self.refresh_commit_stack(commits)

        # Commits that are descendants of the stack need to be rebased too.
        for node in post_stack_children:
            self.hg(["rebase", "--source", node, "--dest", commit["node"]])

    def rebase_commit(self, source_commit, dest_commit):
        self.hg(
            ["rebase"]
            + ["--source", source_commit["node"]]
            + ["--dest", dest_commit["node"]]
        )

    def check_commits_for_submit(self, commits):
        # 'Greatest Common Ancestor'/'Merge Base' should be included in the revset.
        ancestor = self.hg_log("ancestor(%s)" % self.revset, split=False)
        if ancestor not in [c["node"] for c in commits]:
            raise Error(
                "Non-linear commit stack (common ancestor %s missing from stack)"
                % ancestor[:12]
            )

        # Merge base needs to have a public parent.
        parent_phases = self.hg_out(
            ["log", "-T", "{phase} {node}\n", "-r", "parents(%s)" % ancestor]
        )
        for parent in parent_phases:
            (phase, node) = parent.split(" ", 1)
            if phase != "public":
                logger.warning(
                    "%s is based off non-public commit %s" % (ancestor[:12], node[:12])
                )

        # Can't submit merge requests.
        if self.hg_log("%s and merge()" % self.revset):
            raise Error("Commit stack contains a merge commit")

        # mq isn't currently supported.
        if self.has_mq and self.hg_out(["qapplied"]):
            raise Error("Found patches applied with `mq`, unable to continue")

        # Uncommitted changes can interact poorly when we update to a different commit.
        status = self._status()
        if status["T"]:
            err = [
                "%s uncommitted change%s present"
                % (len(status["T"]), " is" if len(status["T"]) == 1 else "s are")
            ]
            err.extend(
                [
                    "Commit changes, or use `hg shelve` to store uncommitted changes,",
                    "restoring with `hg unshelve` after submission",
                ]
            )
            if not self.has_shelve:
                err.append("You can enable the shelve extension via `hg config --edit`")
            raise Error("\n".join(err))

        super(Mercurial, self).check_commits_for_submit(commits)


#
# Git
#


class Git(Repository):
    def __init__(self, path):
        dot_path = os.path.join(path, ".git")
        if not os.path.exists(dot_path):
            raise ValueError("%s: not a git repository" % path)
        logger.debug("found git repo in %s" % path)

        super(Git, self).__init__(path, dot_path)

        if not which("git"):
            raise Error("Failed to find 'git' executable")
        # TODO draw the rest of the owl

        raise NotImplementedError("git support is not yet implemented")


#
# Commit helpers
#


def parse_arc_diff_rev(body):
    m = ARC_DIFF_REV_RE.search(body)
    return m.group(1) if m else None


def parse_bugs(title):
    return BUG_ID_RE.findall(title)


def parse_reviewers(title):
    reviewers = []
    for match in re.finditer(REVIEWERS_RE, title):
        if not match.group(3):
            continue
        reviewers.extend(re.split(LIST_RE, match.group(3)))
    return reviewers


def has_arc_rejections(body):
    return all(r.search(body) for r in ARC_REJECT_RE_LIST)


def augment_commits_from_body(commits):
    """Extract metadata from commit body as fields.

    Adds: rev-id, bug-id, reviewers
    """

    for commit in commits:
        commit["rev-id"] = parse_arc_diff_rev(commit["body"])

        # bug-id
        bug_ids = parse_bugs(commit["title"])
        if bug_ids:
            if len(bug_ids) > 1:
                logger.warning("Multiple bug-IDs found, using %s" % bug_ids[0])
            commit["bug-id"] = bug_ids[0]
        else:
            commit["bug-id"] = None
        if "bug-id-orig" not in commit:
            commit["bug-id-orig"] = commit["bug-id"]

        # reviewers
        commit["reviewers"] = parse_reviewers(commit["title"])

    update_commit_title_previews(commits)


def build_commit_title(commit):
    """Build/update title from commit metadata"""

    # Reviewers.
    title = replace_reviewers(commit["title"], commit["reviewers"])

    # Bug-ID.
    if commit["bug-id"]:
        if BUG_ID_RE.search(title):
            title = BUG_ID_RE.sub("Bug %s" % commit["bug-id"], title)
        else:
            title = "Bug %s - %s" % (commit["bug-id"], title)
    else:
        # This is likely to result in unappealing results.
        title = BUG_ID_RE.sub("", title)

    return title


def update_commit_title_previews(commits):
    """Update title-preview from commit metadata for all commits in stack"""
    for commit in commits:
        commit["title-preview"] = build_commit_title(commit)


def replace_reviewers(commit_description, reviewers):
    """From vct's commitparser"""
    # TODO unit test

    if not reviewers:
        reviewers_str = ""
    else:
        reviewers_str = "r?" + ",".join(reviewers)

    if commit_description == "":
        return reviewers_str

    commit_description = commit_description.splitlines()
    commit_title = commit_description.pop(0)
    commit_description = "\n".join(commit_description)

    if not R_SPECIFIER_RE.search(commit_title):
        commit_title += " " + reviewers_str
    else:
        # replace the first r? with the reviewer list, and all subsequent
        # occurrences with a marker to mark the blocks we need to remove
        # later.
        d = {"first": True}

        def replace_first_reviewer(matchobj):
            if R_SPECIFIER_RE.match(matchobj.group(2)):
                if d["first"]:
                    d["first"] = False
                    return matchobj.group(1) + reviewers_str
                else:
                    return "\0"
            else:
                return matchobj.group(0)

        commit_title = re.sub(REVIEWERS_RE, replace_first_reviewer, commit_title)

        # remove marker values as well as leading separators.  this allows us
        # to remove runs of multiple reviewers and retain the trailing
        # separator.
        commit_title = re.sub(LIST + "\0", "", commit_title)
        commit_title = re.sub("\0", "", commit_title)

    if commit_description == "":
        return commit_title.strip()
    else:
        return commit_title.strip() + "\n" + commit_description


def show_commit_stack(repo, commits, show_rev_urls=False, show_warnings=False):
    """Log the commit stack in a human readable form."""
    for commit in reversed(commits):
        logger.info("%s %s" % (commit["name"], commit["title-preview"]))
        if show_warnings:
            if commit["bug-id-orig"] and commit["bug-id"] != commit["bug-id-orig"]:
                logger.warning(
                    "!! Bug ID changed from %s to %s"
                    % (commit["bug-id-orig"], commit["bug-id"])
                )

            if not commit["reviewers"]:
                logger.warning("!! Missing reviewers")

        if show_rev_urls and commit["rev-id"]:
            logger.warning("-> %sD%s" % (repo.phab_url, commit["rev-id"]))


def arc_out(args, cwd):
    """arc wrapper that logs output"""
    arc_output = check_output(config.arc + args, cwd=cwd, split=False)
    if logger.level != logging.DEBUG:
        logger.info(arc_output)
    return arc_output


def arc_message(template_vars):
    """Build arc commit desc message from the template"""

    # Map `None` to an empty string.
    for name in template_vars.keys():
        if template_vars[name] is None:
            template_vars[name] = ""

    # `depends_on` is optional.
    if "depends_on" not in template_vars:
        template_vars["depends_on"] = ""

    message = ARC_COMMIT_DESC_TEMPLATE.format(**template_vars)
    logger.debug("--- arc message\n%s\n---" % message)
    return message


#
# "submit" Command
#


def update_commits_from_args(commits, args):
    # Build list of reviewers from args.
    reviewers = list(set(args.reviewer)) if args.reviewer else []
    blockers = list(set(args.blocker)) if args.blocker else []
    reviewers += ["%s!" % r.rstrip("!") for r in blockers]

    # Command args always overwrite commit desc.
    for commit in commits:
        if reviewers:
            commit["reviewers"] = reviewers
        if args.bug:
            commit["bug-id"] = args.bug

    # Otherwise honour config setting to always use blockers
    if not reviewers and config.always_blocking:
        for commit in commits:
            commit["reviewers"] = ["%s!" % r.rstrip("!") for r in commit["reviewers"]]

    update_commit_title_previews(commits)


def submit(repo, args):
    if DEBUG or (hasattr(args, "trace") and args.trace):
        config.arc.append("--trace")

    # Find and preview commits to submits.
    commits = repo.commit_stack()
    if not commits:
        raise Error("Failed to find any commits to submit")
    logger.warning(
        "Submitting %s commit%s:" % (len(commits), "" if len(commits) == 1 else "s")
    )

    # Pre-process to load metadata.
    augment_commits_from_body(commits)
    update_commits_from_args(commits, args)

    # Validate commit stack is suitable for review.
    show_commit_stack(repo, commits, show_warnings=True)
    try:
        repo.check_commits_for_submit(commits)
    except Error as e:
        if not args.force:
            raise Error("Unable to submit commits:\n\n%s" % e)
        logger.error("Ignoring issues found with commits:\n\n%s" % e)

    # Show a warning if there are untracked files.
    if config.warn_untracked:
        untracked = repo.untracked()
        if untracked:
            logger.warning(
                "Warning: found %s untracked file%s:"
                % (len(untracked), "" if len(untracked) == 1 else "s")
            )
            if len(untracked) <= 5:
                for filename in untracked:
                    logger.info("  %s" % filename)

    # Confirmation prompt.
    if args.yes:
        pass
    elif config.auto_submit and not args.interactive:
        logger.info(
            "Automatically submitting (as per submit.auto_submit in %s)" % config.name
        )
    else:
        res = prompt(
            "Submit to %s" % PHABRICATOR_URLS.get(repo.phab_url, repo.phab_url),
            ["Yes", "No", "Always"],
        )
        if res == "No":
            return
        if res == "Always":
            config.auto_submit = True
            config.write()

    # Process.
    previous_commit = None
    for commit in commits:
        # Let the user know something's happening.
        if commit["rev-id"]:
            logger.info("\nUpdating revision D%s:" % commit["rev-id"])
        else:
            logger.info("\nCreating new revision:")
        logger.info("%s %s" % (commit["name"], commit["title-preview"]))
        repo.checkout(commit["node"])

        # Create arc-annotated commit description.
        template_vars = dict(
            title=commit["title-preview"],
            body=commit["body"],
            reviewers=", ".join(commit["reviewers"]),
            bug_id=commit["bug-id"],
        )
        if previous_commit:
            template_vars["depends_on"] = "Depends on D%s" % previous_commit["rev-id"]
        message = arc_message(template_vars)

        # Run arc.
        with NamedTemporaryFile() as temp_f:
            temp_f.write(message)
            temp_f.flush()

            arc_args = (
                ["diff"]
                + ["--base", "arc:this"]
                + ["--allow-untracked", "--no-amend", "--no-ansi"]
                + ["--message-file", temp_f.name]
            )
            if commit["rev-id"]:
                arc_args.extend(
                    ["--message", "Revision updated."] + ["--update", commit["rev-id"]]
                )
            else:
                arc_args.append("--create")

            arc_output = arc_out(arc_args, cwd=repo.path)

        # Extract Revision URL.
        m = ARC_OUTPUT_REV_URL_RE.search(arc_output)
        if not m:
            raise Error("Failed to find 'Revision URL' in arc output")
        revision_url = m.group(1)

        # Append/replace div rev url to/in commit description.
        body = commit["body"]
        body = ARC_DIFF_REV_RE.sub("", body).rstrip()
        if body:
            body += "\n"
        body += "\nDifferential Revision: %s" % revision_url

        # Amend the commit if required.
        if commit["title-preview"] != commit["title"] or body != commit["body"]:
            commit["title"] = commit["title-preview"]
            commit["body"] = body
            commit["rev-id"] = parse_arc_diff_rev(commit["body"])
            repo.amend_commit(commit, commits)

        previous_commit = commit

    # Cleanup (eg. strip nodes) and refresh to ensure the stack is right for the
    # final showing.
    repo.cleanup()
    repo.refresh_commit_stack(commits)

    logger.warning("\nCompleted")
    show_commit_stack(repo, commits, show_rev_urls=True)


#
# Self-Updater
#


def get_self_release():
    """Queries github for the most recent release's tag and timestamp"""
    releases_api_url = "https://api.github.com/repos/%s/releases/latest" % SELF_REPO
    logger.debug("fetching %s" % releases_api_url)

    # Grab release json from github's api, using a very short timeout.
    try:
        release = json.load(urllib2.urlopen(releases_api_url, timeout=5))
    except (urllib2.HTTPError, urllib2.URLError) as e:
        raise Error("Failed to check for updates: %s" % e)
    except ValueError:
        raise Error("Malformed response from GitHub when checking for updates")
    logger.debug(release)

    # Grab the published and last-modified timestamps.
    published_at = parse_zulu_time(release["published_at"])
    try:
        m_time = os.path.getmtime(SELF_FILE)
    except OSError as e:
        if e.errno != errno.ENOENT:
            raise
        m_time = 0
    logger.debug("published_at: %s" % datetime.datetime.fromtimestamp(published_at))
    logger.debug("m_time: %s" % datetime.datetime.fromtimestamp(m_time))

    return dict(
        published_at=published_at,
        update_required=published_at > m_time,
        tag=str(release["tag_name"]),
    )


def update_arc():
    """Write the las check and update arc."""
    config.arc_last_check = int(time.time())
    config.write()
    check_call(config.arc + ["upgrade"])


def check_for_updates():
    """Log a message if an update is required/available"""

    # Notify for self updates.
    if (
        config.self_last_check >= 0
        and time.time() - config.self_last_check > SELF_UPDATE_FREQUENCY * 60 * 60
    ):
        config.self_last_check = int(time.time())
        config.write()

        release = get_self_release()

        if release["update_required"]:
            logger.warning("Version %s of `moz-phab` is now available" % release["tag"])
            logger.info("Run `moz-phab self-update` to update")
        else:
            logger.debug("update check not required")

    # Update arc.
    if (
        config.arc_last_check >= 0
        and time.time() - config.arc_last_check > ARC_UPDATE_FREQUENCY * 60 * 60
    ):
        update_arc()


def self_update(args):
    """`self-update` command, updates arc and this script"""
    # Update arc.
    if config.arc_last_check >= 0:
        update_arc()

    # Update moz-phab
    release = get_self_release()

    if not release["update_required"] and not args.force:
        logger.warning("Update of `moz-phab` not required")
        return

    logger.warning("Updating `moz-phab` to v%s" % release["tag"])

    url = "https://raw.githubusercontent.com/%s/%s/moz-phab" % (
        SELF_REPO,
        release["tag"],
    )
    logger.debug("updating '%s' from %s" % (SELF_FILE, url))
    try:
        gh = urllib2.urlopen(url)
        with open(SELF_FILE, "wb") as fh:
            fh.write(gh.read())
        os.chmod(SELF_FILE, stat.S_IRWXU)
    except (urllib2.HTTPError, urllib2.URLError) as e:
        raise Error("Failed to download update: %s" % e)

    logger.info("%s updated" % SELF_FILE)


#
# Main
#


class ColourFormatter(logging.Formatter):
    def __init__(self):
        super(ColourFormatter, self).__init__("%(message)s")
        self.log_colours = {"WARNING": 34, "ERROR": 31}  # blue, red

    def format(self, record):
        result = super(ColourFormatter, self).format(record)
        if HAS_ANSI and record.levelname in self.log_colours:
            result = "\033[%sm%s\033[0m" % (self.log_colours[record.levelname], result)
        return result


def init_logging():
    stdout_handler = logging.StreamHandler(sys.stdout)
    stdout_handler.setFormatter(ColourFormatter())
    logger.addHandler(stdout_handler)
    logger.setLevel(logging.DEBUG if DEBUG else logging.INFO)


def parse_args():
    parser = argparse.ArgumentParser()
    commands = parser.add_subparsers(dest="command", metavar="COMMAND")
    commands.required = True

    # submit

    submit_parser = commands.add_parser(
        "submit", help="Submit commits(s) to Phabricator"
    )
    submit_parser.add_argument(
        "--path", "-p", help="Set path to repository (default: detected)"
    )
    submit_parser.add_argument(
        "--yes",
        "-y",
        action="store_true",
        help="Submit without confirmation (default: %s)" % config.auto_submit,
    )
    submit_parser.add_argument(
        "--interactive",
        "-i",
        action="store_true",
        help="Submit with confirmation (default: %s)" % (not config.auto_submit),
    )
    submit_parser.add_argument(
        "--force",
        "-f",
        action="store_true",
        help="Override sanity checks and force submission; a tool of last resort",
    )
    submit_parser.add_argument(
        "--bug", "-b", help="Set Bug ID for all commits (default: from commit)"
    )
    submit_parser.add_argument(
        "--reviewer",
        "--reviewers",
        "-r",
        action="append",
        help="Set review(s) for all commits (default: from commit)",
    )
    submit_parser.add_argument(
        "--blocker",
        "--blocker",
        "-R",
        action="append",
        help="Set blocking review(s) for all commits (default: from commit)",
    )
    submit_parser.add_argument(
        "start_rev",
        nargs="?",
        default="(auto)",
        help="Start revision of range to submit (default: detected)",
    )
    submit_parser.add_argument(
        "end_rev",
        nargs="?",
        default=".",
        help="End revision of range to submit (default: current commit)",
    )

    # arc informs users to pass --trace for more output, so we need to accept it.
    submit_parser.add_argument("--trace", action="store_true", help=argparse.SUPPRESS)

    submit_parser.set_defaults(func=submit, needs_repo=True)

    # self-update

    update_parser = commands.add_parser("self-update", help="Update review script")
    update_parser.add_argument(
        "--force", "-f", action="store_true", help="Force update even if not necessary"
    )
    update_parser.set_defaults(func=self_update, needs_repo=False)

    return parser.parse_args()


def main():
    global config, HAS_ANSI
    try:
        init_logging()
        config = Config()

        if config.no_ansi:
            HAS_ANSI = False

        if not os.path.exists(config.arc_command) and not which(config.arc_command):
            raise Error(
                "Failed to find '%s' on the system path.\n"
                "Please follow the Phabricator setup guide:\n"
                "%s" % (config.arc_command, GUIDE_URL)
            )

        # Ensure ssl certificates are validated (see PEP 476).
        if hasattr(ssl, "_https_verify_certificates"):
            # PEP 493: "private" API to configure HTTPS defaults without monkeypatching
            # noinspection PyProtectedMember
            ssl._https_verify_certificates()
        else:
            logger.warning(
                "Your version of Python does not validate HTTPS "
                "certificates.  Please consider upgrading to Python 2.7.9 "
                "or later."
            )

        args = parse_args()

        if args.command != "self-update":
            check_for_updates()

        if args.needs_repo:
            repo = repo_from_args(args)
            args.func(repo, args)
            repo.cleanup()

        else:
            args.func(args)

    except KeyboardInterrupt:
        pass
    except Error as e:
        logger.error(e)
        sys.exit(1)
    except Exception as e:
        logger.error(
            traceback.format_exc() if DEBUG else "%s: %s" % (e.__class__.__name__, e)
        )
        sys.exit(1)


if __name__ == "__main__":
    main()
